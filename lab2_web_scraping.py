# -*- coding: utf-8 -*-
"""lab2 web scraping

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s0YP76CwvO02fcuGod9G23T1Ar_sGpZG
"""

import requests

url = "https://news.google.com/home?tab=rn&hl=en-IN&gl=IN&ceid=IN:en"

data = requests.get(url)

data.content

import pandas as pd

data1 = {
    "name" : ["xyz","abc","pqr"],
    "rollno" : [1,2,3],
    "marks" : [25,9,67]
}

data1

df = pd.DataFrame(data1)

import matplotlib as plt

df

df.plot(kind = "box")

from bs4 import BeautifulSoup
import requests
from csv import writer

url= "https://www.pararius.com/apartments/amsterdam?ac=1"
page = requests.get(url)

soup = BeautifulSoup(page.content, 'html.parser')
lists = soup.find_all('section', class_="listing-search-item")

with open('housing.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Title', 'Location', 'Price', 'Area']
    thewriter.writerow(header)

    for list in lists:
        title = list.find('a', class_="listing-search-item__link--title").text.replace('\n', '')
        location = list.find('div', class_="listing-search-item__location").text.replace('\n', '')
        price = list.find('span', class_="listing-search-item__price").text.replace('\n', '')
        area = list.find('span', class_="illustrated-features__description").text.replace('\n', '')

        info = [title, location, price, area]
        thewriter.writerow(info)

from bs4 import BeautifulSoup
import requests
from csv import writer

header = { "cookie":"session-id=260-7955516-9607362; session-id-time=2082787201l; i18n-prefs=INR; ubid-acbin=259-5164195-0864960; session-token=yVlk0J4A1s2VSKZS+m6ENiamOP/QaXVgvHBmaF77fIQyZoA/Xi9i97pyJ4zHP03/qctmL1IV9l1Ls+DD/oPGf7nn8gWW0l0QNfnOjFBiPdWihpaPS1CZ1d9N5PXI4sKOwR0D9iSw0sx5/tPNOZIGD9pvlqktndKgoiQIcm4AzPlQ8cqOPTgSeOwOrjzcTirVnYZmVmx1aF7PiTKqmMFUQn97WpuPwh2cFpL8EyLI7Gw; csm-hit=tb:s-PJT0T51WVZ54MYGMTYTP|1676217761012&t:1676217761856&adb:adblk_no"}
url= "https://www.amazon.in/s?hidden-keywords=B09MH9M5CV+%7C+B0B4N6JVMW+%7C+B09Q5QLHSQ+%7C+B09SGGB687+%7C+B09Q92YBWG+%7C+B09QT8Y9PP+%7C+B09L53YH86+%7C+B09RQM1HHN+%7C+B09WDR8653+%7C+B08WPNPTDD+%7C+B09L55THRG+%7C+B09VPMHSJ6+%7C+B09V7ZJYBN+%7C+B09VPV28W3+%7C+B0B46CJ21J+%7C+B09MM5TSJ7+%7C+B09VPS41Z8+%7C+B09Y5XQFC4+%7C+B0B5H1YB7T+%7C+B09TNWYR3Q+%7C+B09SV2B5SR+%7C+B09R1MMMTH+%7C+B09RQL25ZB+%7C+B09RQKJXNW+%7C+B0B4JRH895+%7C+B09V735YV1+%7C+B09NLR6HJB&pf_rd_i=1320006031&pf_rd_i=1375424031&pf_rd_m=A1K21FY43GMZF8&pf_rd_m=A1K21FY43GMZF8&pf_rd_p=353b3c90-bc15-4f49-a463-37efbe0c4ed4&pf_rd_p=previewPlacement_center-1&pf_rd_r=QG2YDBQM5YEH025897HJ&pf_rd_r=VR4N3D3RE3ERFFGJ379D&pf_rd_s=center-1&pf_rd_s=merchandised-search-12&pf_rd_t=101&pf_rd_t=101&ref=s9_acss_bw_cg_PDPrint_2a1_w"
page = requests.request("GET",url,headers=header)

soup = BeautifulSoup(page.content, 'html.parser')
# lists = soup.find_all('span', class_="a-size-base-plus a-color-base a-text-normal")
lists = soup.find_all('div', class_="sg-col-20-of-24 s-matching-dir sg-col-16-of-20 sg-col sg-col-8-of-12 sg-col-12-of-16")


# print(lists)


# title1 = list.find('span', class_="a-icon-alt")
with open('phone.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['name']
    thewriter.writerow(header)

    for lst in lists:
        # titles = lst.find('span', class_="a-size-base-plus a-color-base a-text-normal")
        titles = lst.text.replace('\n', '')
        print(titles)
        # priceLst = price.text
        # print(priceLst)
        # Review = lst.find('span', class_="a-icon-alt")
        # price = lst.find('span', class_="a-price-whole")


        info = [titles]
        thewriter.writerow(info)

from bs4 import BeautifulSoup
import requests
from csv import writer

header = { "cookie":"session-id=260-7955516-9607362; session-id-time=2082787201l; i18n-prefs=INR; ubid-acbin=259-5164195-0864960; session-token=yVlk0J4A1s2VSKZS+m6ENiamOP/QaXVgvHBmaF77fIQyZoA/Xi9i97pyJ4zHP03/qctmL1IV9l1Ls+DD/oPGf7nn8gWW0l0QNfnOjFBiPdWihpaPS1CZ1d9N5PXI4sKOwR0D9iSw0sx5/tPNOZIGD9pvlqktndKgoiQIcm4AzPlQ8cqOPTgSeOwOrjzcTirVnYZmVmx1aF7PiTKqmMFUQn97WpuPwh2cFpL8EyLI7Gw; csm-hit=tb:s-PJT0T51WVZ54MYGMTYTP|1676217761012&t:1676217761856&adb:adblk_no"}
url= "https://www.amazon.in/s?hidden-keywords=B09MH9M5CV+%7C+B0B4N6JVMW+%7C+B09Q5QLHSQ+%7C+B09SGGB687+%7C+B09Q92YBWG+%7C+B09QT8Y9PP+%7C+B09L53YH86+%7C+B09RQM1HHN+%7C+B09WDR8653+%7C+B08WPNPTDD+%7C+B09L55THRG+%7C+B09VPMHSJ6+%7C+B09V7ZJYBN+%7C+B09VPV28W3+%7C+B0B46CJ21J+%7C+B09MM5TSJ7+%7C+B09VPS41Z8+%7C+B09Y5XQFC4+%7C+B0B5H1YB7T+%7C+B09TNWYR3Q+%7C+B09SV2B5SR+%7C+B09R1MMMTH+%7C+B09RQL25ZB+%7C+B09RQKJXNW+%7C+B0B4JRH895+%7C+B09V735YV1+%7C+B09NLR6HJB&pf_rd_i=1320006031&pf_rd_i=1375424031&pf_rd_m=A1K21FY43GMZF8&pf_rd_m=A1K21FY43GMZF8&pf_rd_p=353b3c90-bc15-4f49-a463-37efbe0c4ed4&pf_rd_p=previewPlacement_center-1&pf_rd_r=QG2YDBQM5YEH025897HJ&pf_rd_r=VR4N3D3RE3ERFFGJ379D&pf_rd_s=center-1&pf_rd_s=merchandised-search-12&pf_rd_t=101&pf_rd_t=101&ref=s9_acss_bw_cg_PDPrint_2a1_w"
page = requests.request("GET",url,headers=header)

soup = BeautifulSoup(page.content, 'html.parser')
lists = soup.find_all('div', class_="sg-col-20-of-24 s-matching-dir sg-col-16-of-20 sg-col sg-col-8-of-12 sg-col-12-of-16")


with open('phone.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['name']
    thewriter.writerow(header)

    for lst in lists:
        titles = lst.text.replace('\n', '')

        info = [titles]
        thewriter.writerow(info)

from bs4 import BeautifulSoup
import requests
from csv import writer

# header = {}

url= "https://www.amazon.in/s?hidden-keywords=B09MH9M5CV+%7C+B0B4N6JVMW+%7C+B09Q5QLHSQ+%7C+B09SGGB687+%7C+B09Q92YBWG+%7C+B09QT8Y9PP+%7C+B09L53YH86+%7C+B09RQM1HHN+%7C+B09WDR8653+%7C+B08WPNPTDD+%7C+B09L55THRG+%7C+B09VPMHSJ6+%7C+B09V7ZJYBN+%7C+B09VPV28W3+%7C+B0B46CJ21J+%7C+B09MM5TSJ7+%7C+B09VPS41Z8+%7C+B09Y5XQFC4+%7C+B0B5H1YB7T+%7C+B09TNWYR3Q+%7C+B09SV2B5SR+%7C+B09R1MMMTH+%7C+B09RQL25ZB+%7C+B09RQKJXNW+%7C+B0B4JRH895+%7C+B09V735YV1+%7C+B09NLR6HJB&pf_rd_i=1320006031&pf_rd_i=1375424031&pf_rd_m=A1K21FY43GMZF8&pf_rd_m=A1K21FY43GMZF8&pf_rd_p=353b3c90-bc15-4f49-a463-37efbe0c4ed4&pf_rd_p=previewPlacement_center-1&pf_rd_r=QG2YDBQM5YEH025897HJ&pf_rd_r=VR4N3D3RE3ERFFGJ379D&pf_rd_s=center-1&pf_rd_s=merchandised-search-12&pf_rd_t=101&pf_rd_t=101&ref=s9_acss_bw_cg_PDPrint_2a1_w"

page = requests.request("GET",url)

# page = requests.request("GET",url,headers=header)

soup = BeautifulSoup(page.content, 'html.parser')
lists = soup.find_all('div', class_="sg-col-20-of-24 s-matching-dir sg-col-16-of-20 sg-col sg-col-8-of-12 sg-col-12-of-16")


with open('phone.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['name']
    thewriter.writerow(header)

    for lst in lists:
        titles = lst.text.replace('\n', '')

        info = [titles]
        thewriter.writerow(info)

soup

